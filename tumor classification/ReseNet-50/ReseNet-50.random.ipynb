{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#libraries\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchmetrics import CohenKappa\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:16.840670Z",
     "end_time": "2025-09-08T12:53:26.345694Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# classes\n",
    "classes = ['glioma tumor', 'meningioma tumor', 'pituitary tumor', 'no tumor']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:26.347694Z",
     "end_time": "2025-09-08T12:53:26.355478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#black and white image dataset\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# calculate the mean and standard deviation\n",
    "def calculate_mean_std_grayscale(dataset_paths):\n",
    "    pixel_sum = 0.\n",
    "    pixel_squared_sum = 0.\n",
    "    total_pixels = 0\n",
    "\n",
    "    for img_path in dataset_paths:\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        img_array = np.array(img) / 255.0\n",
    "        pixels = img_array.flatten()\n",
    "\n",
    "        pixel_sum += pixels.sum()\n",
    "        pixel_squared_sum += np.square(pixels).sum()\n",
    "        total_pixels += pixels.size\n",
    "\n",
    "    mean = pixel_sum / total_pixels\n",
    "    std = np.sqrt(pixel_squared_sum / total_pixels - mean ** 2)\n",
    "\n",
    "    return [mean], [std]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:26.355478Z",
     "end_time": "2025-09-08T12:53:26.371723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset path\n",
    "data_dir = \"./Training\"\n",
    "file_paths, labels = [], []\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            file_paths.append(os.path.join(class_dir, file_name))\n",
    "            labels.append(label)\n",
    "test_dir = \"./Testing\"\n",
    "test_file_paths, test_labels = [], []\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(test_dir, class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        test_file_paths.append(os.path.join(class_dir, file_name))\n",
    "        test_labels.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:26.366723Z",
     "end_time": "2025-09-08T12:53:26.389347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data splitting\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# mean and standard deviation for this dataset\n",
    "mean, std = calculate_mean_std_grayscale(train_paths)\n",
    "print(\"Mean (Grayscale):\", mean, \"Std (Grayscale):\", std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:26.391247Z",
     "end_time": "2025-09-08T12:53:43.712463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# augmentation\n",
    "transform_grayscale = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T12:53:43.717409Z",
     "end_time": "2025-09-08T12:53:43.763976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Class distribution before data augmentation\n",
    "class_counts_before = Counter(train_labels)\n",
    "for class_label, count in class_counts_before.items():\n",
    "    print(f\"class {class_label}: {count}\")\n",
    "# Performing data augmentation for classes with fewer samples\n",
    "max_count = max(class_counts_before.values())\n",
    "\n",
    "augmented_paths = []\n",
    "augmented_labels = []\n",
    "\n",
    "for class_label, count in class_counts_before.items():\n",
    "    if count < max_count:\n",
    "        class_indices = [i for i, label in enumerate(train_labels) if label == class_label]\n",
    "        class_paths = [train_paths[i] for i in class_indices]\n",
    "\n",
    "        num_to_generate = max_count - count\n",
    "        for _ in range(num_to_generate):\n",
    "            original_path = random.choice(class_paths)\n",
    "            image = Image.open(original_path).convert('L')\n",
    "            augmented_image = augmentation_transform(image).unsqueeze(0)\n",
    "\n",
    "            augmented_paths.append(original_path)\n",
    "            augmented_labels.append(class_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# concatenating raw and augmented\n",
    "balanced_train_paths = train_paths + augmented_paths\n",
    "balanced_train_labels = train_labels + augmented_labels\n",
    "balanced_train_dataset_grayscale = BrainTumorDataset(balanced_train_paths, balanced_train_labels,\n",
    "                                                              transform=augmentation_transform)\n",
    "balanced_train_loader_grayscale = DataLoader(balanced_train_dataset_grayscale, batch_size=32, shuffle=True)\n",
    "val_dataset_grayscale = BrainTumorDataset(val_paths, val_labels, transform=transform_grayscale)\n",
    "val_loader_grayscale = DataLoader(val_dataset_grayscale, batch_size=32, shuffle=False)\n",
    "test_dataset_grayscale = BrainTumorDataset(test_file_paths, test_labels, transform=transform_grayscale)\n",
    "test_loader_grayscale = DataLoader(test_dataset_grayscale, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.354880Z",
     "end_time": "2025-08-17T20:26:26.358931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.390042Z",
     "end_time": "2025-08-17T20:26:26.446176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the model ImageNet weights\n",
    "model = models.resnet50(weights=None)\n",
    "\n",
    "# modify the output layer to match the number of classes\n",
    "original_conv = model.conv1\n",
    "model.conv1 = nn.Conv2d(1, original_conv.out_channels, kernel_size=original_conv.kernel_size,\n",
    "                        stride=original_conv.stride, padding=original_conv.padding, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.conv1.weight[:, 0, :, :] = original_conv.weight[:, 0, :, :]\n",
    "# model features\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 4\n",
    "learning_rate = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "num_epochs = 1000\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "# modify the output layer to match the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.399175Z",
     "end_time": "2025-08-17T20:26:26.819513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the model on the validation data\n",
    "def eval_model_grayscale(model, data_loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total, correct = 0., 0.\n",
    "        val_loss = 0.\n",
    "        for data, targets in data_loader:\n",
    "            x_b, y_b = data.to(device), targets.to(device)\n",
    "            logits = model(x_b)\n",
    "            val_loss += criterion(logits, y_b).item()\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1)\n",
    "            correct += (pred == y_b).sum()\n",
    "            total += len(y_b)\n",
    "        val_acc = (100 * correct / total).item()\n",
    "        average_val_loss = val_loss / len(data_loader)\n",
    "        return average_val_loss, val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.822018Z",
     "end_time": "2025-08-17T20:26:26.823024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "def test_model_grayscale(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    y_labels = []\n",
    "    y_preds = []\n",
    "    model.load_state_dict(torch.load('./best_epoch.pth', weights_only=True))\n",
    "    test_p_bar = tqdm(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            acc_test = 100 * correct / total\n",
    "            test_p_bar.set_postfix_str(f'loss={0:.4f}, acuraccy = {acc_test:.4f}%') # Loss در اینجا معنا ندارد\n",
    "            test_p_bar.update()\n",
    "            y_labels.extend(labels.cpu().numpy())\n",
    "            y_preds.extend(predicted.cpu().numpy())\n",
    "        test_p_bar.close()\n",
    "    return acc_test, y_labels, y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.827026Z",
     "end_time": "2025-08-17T20:26:26.828879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model\n",
    "for epoch in range(1, num_epochs):\n",
    "    total, correct = 0, 0\n",
    "    p_bar = tqdm(balanced_train_loader_grayscale)\n",
    "    loss_train, losses_train = 0., 0.\n",
    "    acc_train = 0.0\n",
    "\n",
    "    for image, label in balanced_train_loader_grayscale:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses_train += loss.item()\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        correct += (pred == label).sum().item()\n",
    "        total += len(label)\n",
    "        acc_train = 100 * correct / total\n",
    "        p_bar.set_postfix_str(f'loss={loss.item():.4f}, acc={acc_train:.4f}%')\n",
    "        p_bar.update()\n",
    "    average_loss = losses_train / len(balanced_train_loader_grayscale)\n",
    "    train_losses.append(average_loss)\n",
    "    train_accuracies.append(acc_train)\n",
    "\n",
    "    val_loss, val_acc = eval_model_grayscale(model, val_loader_grayscale, criterion, device)\n",
    "    p_bar.close()\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}%\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current learning rate at epoch {epoch}: {current_lr}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'best_epoch.pth')\n",
    "        patience_counter = 0\n",
    "        print(f\"Patience Counter: {patience_counter}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience Counter: {patience_counter}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    print(\"..... .... ... .. .. .\")\n",
    "\n",
    "print(f\"Best epoch : {best_epoch}\")\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:26:26.833917Z",
     "end_time": "2025-08-17T20:45:48.934536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# test the model\n",
    "test_accuracy, test_labels_all, test_preds_all = test_model_grayscale(model, test_loader_grayscale, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:45:48.934536Z",
     "end_time": "2025-08-17T20:45:52.701944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "test_conf_matrix = confusion_matrix(test_labels_all, test_preds_all)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix,\n",
    "                              display_labels=['glioma', 'meningioma', 'pituitary', 'no tumor'])\n",
    "disp.plot(cmap=plt.cm.Reds, ax=ax, xticks_rotation='horizontal')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),fontsize = 16)\n",
    "ax.set_yticklabels(ax.get_yticklabels(),fontsize = 16)\n",
    "for row in disp.text_:\n",
    "    for text in row:\n",
    "        text.set_fontsize(20)\n",
    "ax.grid(False)\n",
    "plt.title(\"Confusion Matrix for the ResNet Model\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:45:52.703936Z",
     "end_time": "2025-08-17T20:45:53.067967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "target_names = ['glioma tumor', 'meningioma tumor', 'pituitary tumor', 'no tumor']\n",
    "report = classification_report(test_labels_all, test_preds_all, target_names=target_names)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:45:53.065968Z",
     "end_time": "2025-08-17T20:45:53.073845Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CohenKappa metric\n",
    "num_classes = 4\n",
    "kappa = CohenKappa(task='multiclass', num_classes=num_classes)\n",
    "test_preds_all = torch.tensor(test_preds_all)\n",
    "test_labels_all = torch.tensor(test_labels_all)\n",
    "kappa_score = kappa(test_preds_all, test_labels_all)\n",
    "\n",
    "print(f\"Cohen's Kappa: {kappa_score * 100:.4f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-17T20:45:53.076845Z",
     "end_time": "2025-08-17T20:45:55.829542Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
