{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths, self.labels, self.transform = file_paths, labels, transform\n",
    "    def __len__(self): return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.file_paths[idx]).convert('L')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_densenet():\n",
    "    model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "    conv0 = model.features.conv0\n",
    "    new_conv = nn.Conv2d(1, conv0.out_channels, conv0.kernel_size, conv0.stride, conv0.padding, bias=False)\n",
    "    with torch.no_grad(): new_conv.weight[:,0,:,:] = conv0.weight[:,0,:,:]\n",
    "    model.features.conv0 = new_conv\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    return model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_vit():\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        \"google/vit-base-patch16-224\",\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    conv = model.vit.embeddings.patch_embeddings.projection\n",
    "    new_conv = nn.Conv2d(1, conv.out_channels, conv.kernel_size, conv.stride, conv.padding, bias=False)\n",
    "    with torch.no_grad(): new_conv.weight.copy_(conv.weight.mean(dim=1, keepdim=True))\n",
    "    model.vit.embeddings.patch_embeddings.projection = new_conv\n",
    "    model.config.num_channels = 1\n",
    "    model.vit.embeddings.patch_embeddings.num_channels = 1\n",
    "    return model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ---------------------- Ensemble ----------------------\n",
    "class DenseNetViTEnsemble(nn.Module):\n",
    "    def __init__(self, densenet, vit, dw, vw):\n",
    "        super().__init__()\n",
    "        self.densenet, self.vit, self.dw, self.vw = densenet.eval(), vit.eval(), dw, vw\n",
    "        for p in self.densenet.parameters(): p.requires_grad=False\n",
    "        for p in self.vit.parameters(): p.requires_grad=False\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        densenet_probs = F.softmax(self.densenet(x), dim=1)\n",
    "        vit_probs = F.softmax(self.vit(x).logits, dim=1)\n",
    "        return self.dw*densenet_probs + self.vw*vit_probs\n",
    "    def predict(self, x): return torch.argmax(self(x), dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_model(model, loader, vit=False):\n",
    "    model.eval(); correct=total=0; y_labels=[]; y_preds=[]\n",
    "    pbar=tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs).logits if vit else model(imgs)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            total += labels.size(0); correct += (preds==labels).sum().item()\n",
    "            acc=100*correct/total; pbar.set_postfix_str(f'Acc={acc:.2f}%'); pbar.update()\n",
    "            y_labels+=labels.cpu().numpy().tolist(); y_preds+=preds.cpu().numpy().tolist()\n",
    "    pbar.close(); return acc,y_labels,y_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_ensemble(model, loader):\n",
    "    model.eval(); correct=total=0; y_labels=[]; y_preds=[]; all_probs=[]\n",
    "    pbar=tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            probs = model(imgs); preds = torch.argmax(probs,1)\n",
    "            total+=labels.size(0); correct+=(preds==labels).sum().item()\n",
    "            acc=100*correct/total; pbar.set_postfix_str(f'Acc={acc:.2f}%'); pbar.update()\n",
    "            y_labels+=labels.cpu().numpy().tolist(); y_preds+=preds.cpu().numpy().tolist()\n",
    "            all_probs+=probs.cpu().numpy().tolist()\n",
    "    pbar.close(); return acc,y_labels,y_preds,all_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    densenet, vit = create_densenet(), create_vit()\n",
    "    densenet.load_state_dict(torch.load('./best_densenet.pth'))\n",
    "    vit.load_state_dict(torch.load('./best_vit.pth'))\n",
    "    ensemble = DenseNetViTEnsemble(densenet, vit, dw=0.95, vw=0.05).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
