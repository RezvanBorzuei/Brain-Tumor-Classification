{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "from torchmetrics import CohenKappa\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:07:31.223612Z",
     "end_time": "2025-09-08T13:07:45.065017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# classes\n",
    "classes = ['glioma tumor', 'meningioma tumor', 'pituitary tumor', 'no tumor']\n",
    "num_classes = len(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:07:45.068016Z",
     "end_time": "2025-09-08T13:07:45.076257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# black and white image dataset\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def pad_data(file_paths, labels, batch_size):\n",
    "    remainder = len(file_paths) % batch_size\n",
    "    if remainder == 0:\n",
    "        return file_paths, labels\n",
    "    num_to_add = batch_size - remainder\n",
    "    padded_paths = file_paths + random.choices(file_paths, k=num_to_add)\n",
    "    padded_labels = labels + random.choices(labels, k=num_to_add)\n",
    "    return padded_paths, padded_labels\n",
    "\n",
    "\n",
    "# calculate the mean and standard deviation\n",
    "def calculate_mean_std_grayscale(dataset_paths):\n",
    "    pixel_sum = 0.\n",
    "    pixel_squared_sum = 0.\n",
    "    total_pixels = 0\n",
    "\n",
    "    for img_path in dataset_paths:\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        img_array = np.array(img) / 255.0\n",
    "        pixels = img_array.flatten()\n",
    "\n",
    "        pixel_sum += pixels.sum()\n",
    "        pixel_squared_sum += np.square(pixels).sum()\n",
    "        total_pixels += pixels.size\n",
    "\n",
    "    mean = pixel_sum / total_pixels\n",
    "    std = np.sqrt(pixel_squared_sum / total_pixels - mean ** 2)\n",
    "\n",
    "    return [mean], [std]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:07:47.304386Z",
     "end_time": "2025-09-08T13:07:47.311805Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset path\n",
    "data_dir = \"./Training\"\n",
    "file_paths, labels = [], []\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            file_paths.append(os.path.join(class_dir, file_name))\n",
    "            labels.append(label)\n",
    "\n",
    "test_dir = \"./Testing\"\n",
    "test_file_paths, test_labels = [], []\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(test_dir, class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        test_file_paths.append(os.path.join(class_dir, file_name))\n",
    "        test_labels.append(label)\n",
    "\n",
    "# data splitting\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    file_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# mean and standard deviation for this dataset\n",
    "mean, std = calculate_mean_std_grayscale(train_paths)\n",
    "print(\"Mean:\", mean, \"Std:\", std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:08:27.778626Z",
     "end_time": "2025-09-08T13:08:44.926209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# augmentation\n",
    "transform_grayscale = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:08:35.632076Z",
     "end_time": "2025-09-08T13:08:44.927356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Class distribution before data augmentation\n",
    "class_counts_before = Counter(train_labels)\n",
    "for class_label, count in class_counts_before.items():\n",
    "    print(f\"class {class_label}: {count}\")\n",
    "# Performing data augmentation for classes with fewer samples\n",
    "max_count = max(class_counts_before.values())\n",
    "\n",
    "augmented_paths = []\n",
    "augmented_labels = []\n",
    "\n",
    "for class_label, count in class_counts_before.items():\n",
    "    if count < max_count:\n",
    "        class_indices = [i for i, label in enumerate(train_labels) if label == class_label]\n",
    "        class_paths = [train_paths[i] for i in class_indices]\n",
    "\n",
    "        num_to_generate = max_count - count\n",
    "        for _ in range(num_to_generate):\n",
    "            original_path = random.choice(class_paths)\n",
    "            image = Image.open(original_path).convert('L')\n",
    "            augmented_image = augmentation_transform(image).unsqueeze(0)\n",
    "\n",
    "            augmented_paths.append(original_path)\n",
    "            augmented_labels.append(class_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:08:44.932831Z",
     "end_time": "2025-09-08T13:08:47.547949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# concatenating raw and augmented\n",
    "balanced_train_paths = train_paths + augmented_paths\n",
    "balanced_train_labels = train_labels + augmented_labels\n",
    "\n",
    "val_dataset_grayscale = BrainTumorDataset(val_paths, val_labels, transform=transform_grayscale)\n",
    "val_loader_grayscale = DataLoader(val_dataset_grayscale, batch_size=32, shuffle=False)\n",
    "test_dataset_grayscale = BrainTumorDataset(test_file_paths, test_labels, transform=transform_grayscale)\n",
    "test_loader_grayscale = DataLoader(test_dataset_grayscale, batch_size=32, shuffle=False)\n",
    "\n",
    "padded_train_paths, padded_train_labels = pad_data(balanced_train_paths, balanced_train_labels, batch_size=32)\n",
    "balanced_train_dataset_grayscale = BrainTumorDataset(padded_train_paths, padded_train_labels,\n",
    "                                                              transform=augmentation_transform)  # استفاده از داده‌افزایی در آموزش\n",
    "balanced_train_loader_grayscale = DataLoader(balanced_train_dataset_grayscale, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:08:47.551947Z",
     "end_time": "2025-09-08T13:08:47.556071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:08:48.526148Z",
     "end_time": "2025-09-08T13:08:48.537333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=num_classes, ignore_mismatched_sizes=True)\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# modify the model match the number of classes\n",
    "original_conv = model.vit.embeddings.patch_embeddings.projection\n",
    "new_conv = nn.Conv2d(1, original_conv.out_channels, kernel_size=original_conv.kernel_size,\n",
    "                     stride=original_conv.stride, padding=original_conv.padding, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    weight_mean = original_conv.weight.mean(dim=1, keepdim=True)\n",
    "    new_conv.weight.copy_(weight_mean)\n",
    "\n",
    "model.vit.embeddings.patch_embeddings.projection = new_conv\n",
    "\n",
    "# model features\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "learning_rate = 1e-4\n",
    "num_classes = 4\n",
    "model.config.image_size = 224\n",
    "model.config.num_channels = 1\n",
    "model.vit.embeddings.patch_embeddings.num_channels = 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "model = model.to(device)\n",
    "print(model.vit.embeddings.patch_embeddings.projection)\n",
    "print(model.config.num_channels)\n",
    "print(model.vit.config.num_channels)\n",
    "print(model.vit.embeddings.patch_embeddings.num_channels)\n",
    "print(model.vit.embeddings.patch_embeddings.projection)\n",
    "print(model.config.num_channels)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:09:32.925860Z",
     "end_time": "2025-09-08T13:09:39.124557Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the model on the validation data\n",
    "def eval_model(model, data_loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    total, correct = 0., 0.\n",
    "    val_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            x_b, y_b = data.to(device), targets.to(device)\n",
    "            logits = model(x_b).logits\n",
    "            val_loss += criterion(logits, y_b).item()\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1)\n",
    "            correct += (pred == y_b).sum()\n",
    "            total += len(y_b)\n",
    "        val_acc = (100 * correct / total).item()\n",
    "        average_val_loss = val_loss / len(data_loader)\n",
    "        return average_val_loss, val_acc\n",
    "\n",
    "# evaluate the model on the test data\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    y_labels = []\n",
    "    y_preds = []\n",
    "    model.load_state_dict(torch.load('./best_epoch.pth', weights_only=True))\n",
    "    test_p_bar = tqdm(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            acc_test = 100 * correct / total\n",
    "            test_p_bar.set_postfix_str(f'accuracy = {acc_test:.4f}%')\n",
    "            test_p_bar.update()\n",
    "            y_labels.extend(labels.cpu().numpy())\n",
    "            y_preds.extend(predicted.cpu().numpy())\n",
    "        test_p_bar.close()\n",
    "    return acc_test, y_labels, y_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-09-08T13:09:55.430893Z",
     "end_time": "2025-09-08T13:09:55.450618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    total, correct = 0, 0\n",
    "    p_bar = tqdm(balanced_train_loader_grayscale)\n",
    "    losses = 0\n",
    "    acc_train = 0.0\n",
    "    model.train()\n",
    "    for image, label in balanced_train_loader_grayscale:\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(image).logits\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        correct += (pred == label).sum().item()\n",
    "        total += len(label)\n",
    "        acc_train = 100 * correct / total\n",
    "        p_bar.set_postfix_str(f'loss={loss.item():.4f}, acc={acc_train:.4f}%')\n",
    "        p_bar.update()\n",
    "\n",
    "    average_loss = losses / len(balanced_train_loader_grayscale)\n",
    "    train_losses.append(average_loss)\n",
    "    train_accuracies.append(acc_train)\n",
    "\n",
    "    val_loss, val_acc = eval_model(model, val_loader_grayscale, criterion, device)\n",
    "    #scheduler.step(val_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    p_bar.close()\n",
    "\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}%\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current learning rate at epoch {epoch}: {current_lr}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'best_epoch.pth')\n",
    "        patience_counter = 0\n",
    "        print(f\"Patience Counter: {patience_counter}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience Counter: {patience_counter}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(\"..... .... ... .. .. .\")\n",
    "\n",
    "print(f\"Best epoch : {best_epoch}\")\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-20T09:25:00.708124Z",
     "end_time": "2025-08-20T09:36:55.916290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# test the model\n",
    "test_accuracy, test_labels_all, test_preds_all = test_model(model, test_loader_grayscale, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-20T09:36:55.925127Z",
     "end_time": "2025-08-20T09:36:59.777127Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "test_conf_matrix = confusion_matrix(test_labels_all, test_preds_all)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix\n",
    "                              ,display_labels=['glioma', 'meningioma', 'pituitary', 'no tumor'])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation='horizontal')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),fontsize = 16)\n",
    "ax.set_yticklabels(ax.get_yticklabels(),fontsize = 16)\n",
    "for row in disp.text_:\n",
    "    for text in row:\n",
    "        text.set_fontsize(20)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "ax.grid(False)\n",
    "plt.title(\"Confusion Matrix for the ViT-Base Model\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-20T09:36:59.779127Z",
     "end_time": "2025-08-20T09:37:00.114078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "target_names = ['glioma tumor', 'meningioma tumor','pituitary tumor', 'no tumor']\n",
    "report = classification_report(test_labels_all, test_preds_all, target_names=[str(i) for i in target_names])\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-20T09:37:00.116079Z",
     "end_time": "2025-08-20T09:37:00.125321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CohenKappa metric\n",
    "num_classes = 4\n",
    "kappa = CohenKappa(task='multiclass', num_classes=num_classes)\n",
    "test_preds_all = torch.tensor(test_preds_all)\n",
    "test_labels_all = torch.tensor(test_labels_all)\n",
    "kappa_score = kappa(test_preds_all, test_labels_all)\n",
    "\n",
    "print(f\"Cohen's Kappa: {kappa_score * 100:.4f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-08-20T09:37:00.127320Z",
     "end_time": "2025-08-20T09:37:00.587861Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
